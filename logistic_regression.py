# -*- coding: utf-8 -*-
"""logistic regression.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/140-MH9LV7kBZD1TOhO2O4KEwvoqMvl64
"""

import pandas as pd
file=pd.read_csv("/content/alzheimers_disease_data.csv")
print(file)

file.info()

uni=file['DoctorInCharge'].unique()
print(uni)

filenew=file.drop(['DoctorInCharge'],axis=1)

filenew.info()

import seaborn as sns
sns.pairplot(filenew)

from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import chi2
x=filenew.drop(['Diagnosis'],axis=1)
y=filenew['Diagnosis']
fs=SelectKBest(score_func=chi2,k=33)
fs.fit(x,y)
s = pd.DataFrame([fs.feature_names_in_,fs.scores_])
s=s.T
s1 = s.sort_values(by=1, ascending=False)
s1

filenew.drop(['PatientID','SleepQuality','BMI','EducationLevel','SystolicBP','Hypertension','CardiovascularDisease','Diabetes','FamilyHistoryAlzheimers',\
              'Disorientation','HeadInjury','PersonalityChanges','Depression','CholesterolTotal','Ethnicity',\
             'Confusion','Gender','AlcoholConsumption','DietQuality','DiastolicBP','DifficultyCompletingTasks','PhysicalActivity',\
              'Age','Smoking','Forgetfulness'],axis=1,inplace=True)

filenew.info()

x=filenew.drop(['Diagnosis'],axis=1)
y=filenew['Diagnosis']
print(x.shape,y.shape)

x.columns

from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

X = filenew.drop(['Diagnosis'],axis=1)
y = filenew['Diagnosis']
X_train, X_test,y_train, y_test = train_test_split(X, y,test_size=0.20, random_state=23)





clf = LogisticRegression(penalty='l1', dual=False, tol=0.0001, C=0.09, fit_intercept=True, intercept_scaling=1,
                         class_weight='balanced', random_state=None, solver='liblinear', max_iter=100,
                         multi_class='ovr', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None)


clf.fit(X_train, y_train)

y_pred = clf.predict(X_test)

acc = accuracy_score(y_test, y_pred)
acc2=accuracy_score(y_train,clf.predict(X_train))
print("Logistic Regression model accuracy (in %):", acc*100)
print("Logistic Regression model accuracy (in %):", acc2*100)

print(y_pred.dtype)

sns.histplot(filenew['Diagnosis'])

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

X = filenew.drop(['Diagnosis'], axis=1)
y = filenew['Diagnosis']
cm = confusion_matrix(y_test, y_pred)

# Display the confusion matrix
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=clf.classes_)
disp.plot()

plt.show()

print(cm)
TP = 224
FP = 46
FN = 19
TN = 141

accuracy=(TP+TN)/(TP+FP+FN+TN)
print(accuracy)

precision=TP/(TP+FP)
print(precision)

recall=TP/(TP+FN)
print(recall)

fscore=(2*precision*recall)/(precision+recall)
print(fscore)

fpr=FP/(FP+TN)
print(fpr)

tpr=TP/(TP+FN)
print(tpr)

fnr=FN/(TP+FN)
print(fnr)

tnr=TN/(FP+TN)
print(tnr)

from sklearn.metrics import roc_curve, auc

fpr, tpr, thresholds = roc_curve(y_test, y_pred)
roc_auc = auc(fpr, tpr)
# Plot the ROC curve
plt.figure()
plt.plot(fpr, tpr, label='ROC curve (area = %0.4f)' % roc_auc)
plt.plot([0, 1], [0, 1], 'k--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve for Breast Cancer Classification')
plt.legend()
plt.show()